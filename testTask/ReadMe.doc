Task2.py- !!!! 

Тестовая задача:
«Задача: написать программу на Python, которая делает следующие действия:
1. Создает 50 zip-архивов, в каждом 100 xml файлов со случайными данными следующей структуры:
<root>
	<var name=’id’ value=’<случайное уникальное строковое значение>’/>
	<var name=’level’ value=’<случайное число от 1 до 100>’/>
	<objects>
		<object name=’<случайное строковое значение>’/>
		<object name=’<случайное строковое значение>’/>
		…
	</objects>
</root>
В тэге objects случайное число (от 1 до 10) вложенных тэгов object.

2. Обрабатывает директорию с полученными zip архивами, разбирает вложенные xml файлы и формирует 2 csv файла:
Первый: id, level - по одной строке на каждый xml файл
Второй: id, object_name - по отдельной строке для каждого тэга object (получится от 1 до 10 строк на каждый xml файл)

Очень желательно сделать так, чтобы задание 2 эффективно использовало ресурсы многоядерного процессора.
Также желательно чтобы программа работала быстро.
В качестве результата нужно прислать исполняемый код программы.

Также мы хотели бы получить от вас комментарий по выполнению тестового задания. Он не должен быть очень большим. Нам интересно было бы узнать:
Примерную оценку времени, которое вы потратили на выполнение задания;
Комментарии по коду, почему выбран тот или иной способ решения;
Возникали ли проблемы при выполнении тестового.



Мое решение:
Для решения проблемы использования всех ядер процессора в обход GIL был выбран многопроцессный подход. Использование классов обеспечило пространство имен внутри класса, что удобно, в том числе, для решения отдельных двух задач тестового задания. Функция map в применении с multiprocess позволили сократить количество кода и время вычисления.

Также были протестированы:
1) Была вероятность ускорения процесса за счет вызова функции записи файл меньшего количества раз, но с большим объемом. Для чего необходима реализации межпроцессного обмена данными, с этой целью был протестирован Queue, что привело к потерям времени (уменьшению эффективности программы). Я отказался от Queue.
2) Дополнительное разбиение каждого процесса (4 ядра = 4 процесса) по обработке архивов на потоки (theards) улучшения временных показателей не обеспечило, а код усложнило. От разбиения процессов на потоки отказался.


Программа протестирована на:
+ (CPU i3-2100, 3.10GHz) «Linux Debian 8» с Python 2.7.9 и Python 3.4.2 , были получены результаты соответственно: 1-я задача ~ 0.71 с, 2-я задача ~ 0.205 с и
1-я задача ~ 0.92 с, 2-я задача ~ 0.206 с.

+ Windows 10

Решение этой задачи потребовало время на знакомство с модулями threading, multiprocessing, multiprocess, общее затраченное время (изучение методов библиотек, написание кода, тестирование и рефакторинг) я затратил примерно 23 часа. После изучение модулей аналогичную задачу решу значительно быстрее.

Выполнять тестовое задание было интересно. Буду рад сотрудничеству с Вашей компанией.
 




Для использования всей мощи многоядерного процессора рассматривались инструменты модулей: subprocess,  threading, multiprocessing, multiprocess. Выбран был multiprocess, как 




 выбран модуль multiprocess, который содержит наиболее простые методы распаралелливания процессов.

При выполнении тестового задания для работы с zip-архивами был выбран модуль zipfile, как наиболее простой. 


В программе используется библиотека multiprocess, которую надо установить вручную:
(sudo pip install multiprocess,...)

